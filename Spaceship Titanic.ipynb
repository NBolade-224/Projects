{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC  \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "Allmodels = [XGBClassifier(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier(), LinearSVC(), SVC(), SGDClassifier(), KNeighborsClassifier(), GaussianNB()]\n",
    "SpaceTitanicTrain = pd.read_csv(\"C:\\\\Users\\\\nickb\\\\Desktop\\Spaceship Titanic\\\\train (1).csv\")\n",
    "SpaceTianicTest = pd.read_csv(\"C:\\\\Users\\\\nickb\\\\Desktop\\\\Spaceship Titanic\\\\test (1).csv\")\n",
    "#SpaceTitanicTrain[['CryoSleep', 'VIP', 'Transported']] = (SpaceTitanicTrain[['CryoSleep', 'VIP', 'Transported']] == True ).astype(int)\n",
    "SpaceTitanicTrain.replace({'Europa': 1, 'Earth': 0, 'Mars' : 3}, inplace=True)\n",
    "SpaceTianicTest.replace({'Europa': 1, 'Earth': 0, 'Mars' : 3}, inplace=True)\n",
    "\n",
    "SpaceTitanicTrain.replace({True: 1, False : 0}, inplace=True)\n",
    "SpaceTianicTest.replace({True: 1, False : 0}, inplace=True)\n",
    "\n",
    "SpaceTitanicTrain.replace({'TRAPPIST-1e': 1, 'PSO J318.5-22': 0, '55 Cancri e' : 3}, inplace=True)\n",
    "SpaceTianicTest.replace({'TRAPPIST-1e': 1, 'PSO J318.5-22': 0, '55 Cancri e' : 3}, inplace=True)\n",
    "SpaceTitanicTrain.columns = SpaceTitanicTrain.columns.str.replace(' ', '')\n",
    "SpaceTianicTest.columns = SpaceTianicTest.columns.str.replace(' ', '')\n",
    "\n",
    "#SpaceTianicTest[\"Transported\"] = SpaceTianicTest[\"Transported\"].astype(int)\n",
    "\n",
    "\n",
    "#SpaceTianicTest[\"Transported\"] = SpaceTianicTest[\"Transported\"].astype(int)\n",
    "\n",
    "SpaceTitanicTrain.replace({'true': 1, 'false': 0}, inplace=True)\n",
    "SpaceTianicTest.replace({'true': 1, 'false': 0}, inplace=True)\n",
    "\n",
    "# SpaceTitanTransported = SpaceTitanicTrain[(SpaceTitanicTrain['Transported'] == 1)]\n",
    "# PeopleinCrysleep = SpaceTitanicTrain[(SpaceTitanicTrain['CryoSleep'] == 1)]\n",
    "ALlfeatures = ['HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'Age', 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "#TruwALlfeatures = ['PassengerId', 'HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'Age', 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Name']\n",
    "# ALlfeaturesLINEARVALUES = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "# SpaceTitanicTrain['Orderedanyluxory'] = SpaceTitanicTrain.apply (lambda row: int((row['FoodCourt']+ row['Spa'] + row['VRDeck']) > 0), axis=1)\n",
    "# SpaceTianicTest['Orderedanyluxory'] = SpaceTianicTest.apply (lambda row: int((row['FoodCourt']+ row['Spa'] + row['VRDeck']) > 0), axis=1)\n",
    "# SpaceTitanicTrain.fillna(method = 'ffill', inplace = True)\n",
    "# SpaceTianicTest.fillna(method = 'ffill', inplace = True)\n",
    "\n",
    "\n",
    "# for x in ['Orderedanyluxory']:\n",
    "#     SpaceTitanicTrain[x].value_counts().plot(kind = 'pie' ,autopct = '.%2f')\n",
    "#     plt.show()\n",
    "#     SpaceTitanTransported[x].value_counts().plot(kind = 'pie' ,autopct = '.%2f')\n",
    "#     plt.show()\n",
    "\n",
    "# for grrh in range(1,25):\n",
    "#     FeaturesForML = ['CryoSleep','HomePlanet','Destination','Orderedanyluxory']\n",
    "#     y = SpaceTitanicTrain.Transported ### Prediction target\n",
    "#     X = SpaceTitanicTrain[FeaturesForML]\n",
    "#     train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 24, test_size=0.33)  #test_size = 0.33\n",
    "#     clf = DecisionTreeClassifier(max_depth=grrh, random_state=573478,criterion=\"gini\", min_samples_leaf=5)  # 'gini'\n",
    "#     gh = clf.fit(train_X, train_y)\n",
    "#     g = pd.get_dummies(SpaceTianicTest[FeaturesForML])\n",
    "#     Prediction = clf.predict(g)\n",
    "#     accuracy_score(val_y, clf.predict(val_X))\n",
    "\n",
    "# for k in range(1,6):\n",
    "#     for o in [LogisticRegression(random_state=1), GaussianNB(),RandomForestClassifier(max_leaf_nodes=50, random_state=1)]:\n",
    "#         FeaturesForML = ['CryoSleep','HomePlanet','Destination','Orderedanyluxory']\n",
    "#         y = SpaceTitanicTrain.Transported ### Prediction target\n",
    "#         x = SpaceTitanicTrain[FeaturesForML]\n",
    "#         train_X, val_X, train_y, val_y = train_test_split(x, y, random_state = k, test_size=0.33)\n",
    "#         Titanic1_model = o\n",
    "#         Titanic1_model.fit(train_X, train_y)\n",
    "#         g = pd.get_dummies(SpaceTianicTest[FeaturesForML])\n",
    "#         accuracy_score(val_y, Titanic1_model.predict(val_X))\n",
    "#     print()\n",
    "#     print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#output = pd.DataFrame({'PassengerId': SpaceTianicTest.PassengerId, 'Transported': Prediction})\n",
    "# output.to_csv('submission1.csv', index=False)\n",
    "# print(\"Your submission was successfully saved!\")\n",
    "\n",
    "#plt.figure(dpi = 450)\n",
    "\n",
    "# for x in ALlfeaturesLINEARVALUES:\n",
    "#     TransportedFalse = SpaceTitanicTrain['Transported'] == 0\n",
    "#     TransportedTrue = SpaceTitanicTrain['Transported'] == 1\n",
    "#     sns.histplot(SpaceTitanicTrain[TransportedFalse][x],color='red')\n",
    "#     sns.histplot(SpaceTitanicTrain[TransportedTrue][x])\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modellist = [RandomForestClassifier(),XGBClassifier(eval_metric='logloss',use_label_encoder=False),LogisticRegression(),KNeighborsClassifier()]  ## SVC()\n",
    "for models in modellist:\n",
    "    scores = []\n",
    "    for states in range(20,100):\n",
    "        y = SpaceTitanicTrain.Transported ### Prediction target\n",
    "        X = SpaceTitanicTrain[ALlfeatures]\n",
    "        train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = states, test_size=0.5)  #test_size = 0.33\n",
    "        categorical_cols = [cname for cname in train_X.columns if train_X[cname].nunique() < 100 and train_X[cname].dtype == \"object\"]\n",
    "        numerical_cols = [cname for cname in train_X.columns if train_X[cname].dtype in ['int64', 'float64']]   ### THIS REMOVES CAT COLUMNS THAT ARE WAY TOO LARGE THAT HAVE LITTLE IN COMMON,                                                                                                            ### SINCE NO STATISTICAL MEANING CAN BE FOUND FROM THEM, SUCH AS UNIQUE ADDRESS WITH NO REFERENCE TO POST CODES ETC.\n",
    "        my_cols = categorical_cols + numerical_cols\n",
    "        X_train = train_X[my_cols].copy()\n",
    "        X_valid = val_X[my_cols].copy()\n",
    "        numerical_transformer = SimpleImputer(strategy='constant')   ### IMPUTATAES (REPLACES MISSING VALUES)\n",
    "        categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),('onehot', OneHotEncoder(handle_unknown='ignore'))])  ### IMPUTES AND ONEHOT ENCODES\n",
    "        preprocessor = ColumnTransformer(transformers=[('num', numerical_transformer, numerical_cols),('cat', categorical_transformer, categorical_cols)])   ### BUNDLES TRANSFORMERS TOGETHER\n",
    "        # SpaceTitanicTrain[\"CryoSleep\"] = SpaceTitanicTrain[\"CryoSleep\"].astype(int)\n",
    "        # SpaceTitanicTrain[\"Transported\"] = SpaceTitanicTrain[\"CryoSleep\"].astype(int)\n",
    "        my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),('model', models)])\n",
    "        gh = my_pipeline.fit(X_train, train_y)   \n",
    "        g = pd.get_dummies(SpaceTianicTest[ALlfeatures])\n",
    "        Prediction = my_pipeline.predict(g)\n",
    "        scores.append(accuracy_score(val_y, my_pipeline.predict(X_valid))) \n",
    "    mean = sum(scores) / len(scores)\n",
    "    print(str(models))\n",
    "    print(max(scores))\n",
    "    print(min(scores))\n",
    "    print(mean)\n",
    "    print('next')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Allmodels\n",
    "modellist = [XGBClassifier(eval_metric='logloss',use_label_encoder=False, max_depth=5),LogisticRegression(max_iter=1001)]  ## SVC()\n",
    "for models in modellist:\n",
    "    scores = []\n",
    "    for states in range(50,500):\n",
    "        y = SpaceTitanicTrain.Transported ### Prediction target\n",
    "        X = SpaceTitanicTrain[ALlfeatures]\n",
    "        train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = states, test_size=0.5)  #test_size = 0.33\n",
    "        categorical_cols = [cname for cname in train_X.columns if train_X[cname].nunique() < 100 and train_X[cname].dtype == \"object\"]\n",
    "        numerical_cols = [cname for cname in train_X.columns if train_X[cname].dtype in ['int64', 'float64']]   ### THIS REMOVES CAT COLUMNS THAT ARE WAY TOO LARGE THAT HAVE LITTLE IN COMMON,                                                                                                            ### SINCE NO STATISTICAL MEANING CAN BE FOUND FROM THEM, SUCH AS UNIQUE ADDRESS WITH NO REFERENCE TO POST CODES ETC.\n",
    "        my_cols = categorical_cols + numerical_cols\n",
    "        X_train = train_X[my_cols].copy()\n",
    "        X_valid = val_X[my_cols].copy()\n",
    "        numerical_transformer = SimpleImputer(strategy='constant')   ### IMPUTATAES (REPLACES MISSING VALUES)\n",
    "        categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),('onehot', OneHotEncoder(handle_unknown='ignore'))])  ### IMPUTES AND ONEHOT ENCODES\n",
    "        preprocessor = ColumnTransformer(transformers=[('num', numerical_transformer, numerical_cols),('cat', categorical_transformer, categorical_cols)])   ### BUNDLES TRANSFORMERS TOGETHER\n",
    "        # SpaceTitanicTrain[\"CryoSleep\"] = SpaceTitanicTrain[\"CryoSleep\"].astype(int)\n",
    "        # SpaceTitanicTrain[\"Transported\"] = SpaceTitanicTrain[\"CryoSleep\"].astype(int)\n",
    "        my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),('model', models)])\n",
    "        gh = my_pipeline.fit(X_train, train_y)   \n",
    "        g = pd.get_dummies(SpaceTianicTest[ALlfeatures])\n",
    "        Prediction = my_pipeline.predict(g)\n",
    "        scores.append(accuracy_score(val_y, my_pipeline.predict(X_valid))) \n",
    "    mean = sum(scores) / len(scores)\n",
    "    print(str(models))\n",
    "    print(max(scores))\n",
    "    print(min(scores))\n",
    "    print(mean)\n",
    "    print('next')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOGISTIC REGRESSION WITH SCORE OF 0.789\n",
    "\n",
    "y = SpaceTitanicTrain.Transported ### Prediction target\n",
    "X = SpaceTitanicTrain[ALlfeatures]\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 350, test_size=0.5)  #test_size = 0.33\n",
    "categorical_cols = [cname for cname in train_X.columns if train_X[cname].nunique() < 100 and train_X[cname].dtype == \"object\"]\n",
    "numerical_cols = [cname for cname in train_X.columns if train_X[cname].dtype in ['int64', 'float64']]   ### THIS REMOVES CAT COLUMNS THAT ARE WAY TOO LARGE THAT HAVE LITTLE IN COMMON,                                                                                                            ### SINCE NO STATISTICAL MEANING CAN BE FOUND FROM THEM, SUCH AS UNIQUE ADDRESS WITH NO REFERENCE TO POST CODES ETC.\n",
    "my_cols = categorical_cols + numerical_cols\n",
    "X_train = train_X[my_cols].copy()\n",
    "X_valid = val_X[my_cols].copy()\n",
    "numerical_transformer = SimpleImputer(strategy='constant')   ### IMPUTATAES (REPLACES MISSING VALUES)\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),('onehot', OneHotEncoder(handle_unknown='ignore'))])  ### IMPUTES AND ONEHOT ENCODES\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numerical_transformer, numerical_cols),('cat', categorical_transformer, categorical_cols)])   ### BUNDLES TRANSFORMERS TOGETHER\n",
    "\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),('model', LogisticRegression(max_iter=1001))])\n",
    "gh = my_pipeline.fit(X_train, train_y)   \n",
    "g = pd.get_dummies(SpaceTianicTest[ALlfeatures])\n",
    "Prediction = my_pipeline.predict(g)\n",
    "accuracy_score(val_y, my_pipeline.predict(X_valid))\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': SpaceTianicTest.PassengerId, 'Transported': Prediction})\n",
    "output.replace({1: True, 0 : False}, inplace=True)\n",
    "output.to_csv('submissionSpaceShipTitanic.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")\n",
    "\n",
    "### THIS GETS ME TO TOP 55% WITH SCORE OF 0.789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              eval_metric='logloss', gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=None)\n",
      "0.8022079116835327\n",
      "0.7755289788408464\n",
      "0.7879300827966881\n",
      "next\n",
      "LogisticRegression(max_iter=1001)\n",
      "0.8008279668813247\n",
      "0.7718491260349586\n",
      "0.7829990800367986\n",
      "next\n",
      "RandomForestClassifier()\n",
      "0.8049678012879485\n",
      "0.7695492180312787\n",
      "0.7834406623735051\n",
      "next\n"
     ]
    }
   ],
   "source": [
    "modellist = [XGBClassifier(eval_metric='logloss',use_label_encoder=False, max_depth=5),LogisticRegression(max_iter=1001)]  ## SVC()\n",
    "Allmodels = [XGBClassifier(eval_metric='logloss',use_label_encoder=False), LogisticRegression(max_iter=1001), RandomForestClassifier()]\n",
    "for models in Allmodels:\n",
    "    scores = []\n",
    "    for states in range(50,75):\n",
    "        y = SpaceTitanicTrain.Transported ### Prediction target\n",
    "        X = SpaceTitanicTrain[ALlfeatures]\n",
    "        train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = states, test_size=0.25)  #test_size = 0.33\n",
    "        categorical_cols = [cname for cname in train_X.columns if train_X[cname].nunique() < 100 and train_X[cname].dtype == \"object\"]\n",
    "        numerical_cols = [cname for cname in train_X.columns if train_X[cname].dtype in ['int64', 'float64']]   ### THIS REMOVES CAT COLUMNS THAT ARE WAY TOO LARGE THAT HAVE LITTLE IN COMMON,                                                                                                            ### SINCE NO STATISTICAL MEANING CAN BE FOUND FROM THEM, SUCH AS UNIQUE ADDRESS WITH NO REFERENCE TO POST CODES ETC.\n",
    "        my_cols = categorical_cols + numerical_cols\n",
    "        X_train = train_X[my_cols].copy()\n",
    "        X_valid = val_X[my_cols].copy()\n",
    "        numerical_transformer = SimpleImputer(strategy='constant')   ### IMPUTATAES (REPLACES MISSING VALUES)\n",
    "        categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),('onehot', OneHotEncoder(handle_unknown='ignore'))])  ### IMPUTES AND ONEHOT ENCODES\n",
    "        preprocessor = ColumnTransformer(transformers=[('num', numerical_transformer, numerical_cols),('cat', categorical_transformer, categorical_cols)])   ### BUNDLES TRANSFORMERS TOGETHER\n",
    "        # SpaceTitanicTrain[\"CryoSleep\"] = SpaceTitanicTrain[\"CryoSleep\"].astype(int)\n",
    "        # SpaceTitanicTrain[\"Transported\"] = SpaceTitanicTrain[\"CryoSleep\"].astype(int)\n",
    "        my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),('model', models)])\n",
    "        gh = my_pipeline.fit(X_train, train_y)   \n",
    "        g = pd.get_dummies(SpaceTianicTest[ALlfeatures])\n",
    "        Prediction = my_pipeline.predict(g)\n",
    "        scores.append(accuracy_score(val_y, my_pipeline.predict(X_valid))) \n",
    "    mean = sum(scores) / len(scores)\n",
    "    print(str(models))\n",
    "    print(max(scores))\n",
    "    print(min(scores))\n",
    "    print(mean)\n",
    "    print('next')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86b62185bc97c39efc21655c4fe9442102aed1230b4709b1ebf59ac10e900490"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
